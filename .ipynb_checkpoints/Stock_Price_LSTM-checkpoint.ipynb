{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Amazon Stock Prediction Using Yahoo Finance + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Download data using the Yahoo Finance API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Read Data using yahoo finance\n",
    "data = yf.download(\n",
    "    tickers=['AMZN'],\n",
    "    # use \"period\" instead of start/end\n",
    "    # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "    # (optional, default is '1mo')\n",
    "    period=\"max\",\n",
    "    # fetch data by interval (including intraday if period < 60 days)\n",
    "    # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "    # (optional, default is '1d')\n",
    "    interval=\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                    Open         High          Low        Close    Adj Close  \\\n",
      "Date                                                                          \n",
      "1997-05-15     2.437500     2.500000     1.927083     1.958333     1.958333   \n",
      "1997-05-16     1.968750     1.979167     1.708333     1.729167     1.729167   \n",
      "1997-05-19     1.760417     1.770833     1.625000     1.708333     1.708333   \n",
      "1997-05-20     1.729167     1.750000     1.635417     1.635417     1.635417   \n",
      "1997-05-21     1.635417     1.645833     1.375000     1.427083     1.427083   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2021-05-27  3256.000000  3260.360107  3230.040039  3230.110107  3230.110107   \n",
      "2021-05-28  3242.000000  3247.989990  3219.699951  3223.070068  3223.070068   \n",
      "2021-06-01  3243.500000  3250.979980  3209.060059  3218.649902  3218.649902   \n",
      "2021-06-02  3223.100098  3235.000000  3208.000000  3233.989990  3233.989990   \n",
      "2021-06-03  3204.229980  3214.435059  3184.030029  3187.010010  3187.010010   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "1997-05-15  72156000  \n",
      "1997-05-16  14700000  \n",
      "1997-05-19   6106800  \n",
      "1997-05-20   5467200  \n",
      "1997-05-21  18853200  \n",
      "...              ...  \n",
      "2021-05-27   2561200  \n",
      "2021-05-28   2329800  \n",
      "2021-06-01   2430000  \n",
      "2021-06-02   2012900  \n",
      "2021-06-03   2398293  \n",
      "\n",
      "[6053 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(data.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Apply MinMaxScalar, or other normalizing methods of your choice. Since we only use the close prices, we can directly \n",
    "apply it before splitting into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "closes = data['Close'].values\n",
    "scaler = MinMaxScaler()\n",
    "closes_scaled = scaler.fit_transform(closes.reshape(-1, 1))\n",
    "closes_scaled = closes_scaled.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.95833302 1.72916698 1.70833302 1.63541698 1.42708302]\n",
      "[1.59345999e-04 9.44274388e-05 8.85255550e-05 6.78697723e-05\n",
      " 8.85255550e-06]\n"
     ]
    }
   ],
   "source": [
    "print(closes[:5])\n",
    "print(closes_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Create rolling prices. Continuously create arrays of a set window size and append to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_rolling = 30\n",
    "\n",
    "#Create the 31 day rolling prices\n",
    "header = [\"day \" + str(i) for i in range(1, (num_rolling + 1 + 1))]\n",
    "df = []\n",
    "for i in range(num_rolling, len(closes)):\n",
    "    arr = []\n",
    "    for j in range(i-num_rolling, i+1):\n",
    "        arr.append(closes_scaled[j])\n",
    "    df.append(np.array(arr))\n",
    "df = pd.DataFrame(df, columns=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          day 1     day 2     day 3     day 4     day 5     day 6     day 7  \\\n",
      "0     0.000159  0.000094  0.000089  0.000068  0.000009  0.000000  0.000030   \n",
      "1     0.000094  0.000089  0.000068  0.000009  0.000000  0.000030  0.000053   \n",
      "2     0.000089  0.000068  0.000009  0.000000  0.000030  0.000053  0.000038   \n",
      "3     0.000068  0.000009  0.000000  0.000030  0.000053  0.000038  0.000031   \n",
      "4     0.000009  0.000000  0.000030  0.000053  0.000038  0.000031  0.000030   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "6018  0.956839  0.962604  0.954834  0.944261  0.952004  0.936995  0.946015   \n",
      "6019  0.962604  0.954834  0.944261  0.952004  0.936995  0.946015  0.965312   \n",
      "6020  0.954834  0.944261  0.952004  0.936995  0.946015  0.965312  0.967700   \n",
      "6021  0.944261  0.952004  0.936995  0.946015  0.965312  0.967700  0.979335   \n",
      "6022  0.952004  0.936995  0.946015  0.965312  0.967700  0.979335  0.982963   \n",
      "\n",
      "         day 8     day 9    day 10  ...    day 22    day 23    day 24  \\\n",
      "0     0.000053  0.000038  0.000031  ...  0.000050  0.000031  0.000032   \n",
      "1     0.000038  0.000031  0.000030  ...  0.000031  0.000032  0.000032   \n",
      "2     0.000031  0.000030  0.000032  ...  0.000032  0.000032  0.000037   \n",
      "3     0.000030  0.000032  0.000024  ...  0.000032  0.000037  0.000030   \n",
      "4     0.000032  0.000024  0.000006  ...  0.000037  0.000030  0.000032   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "6018  0.965312  0.967700  0.979335  ...  0.912593  0.926046  0.915251   \n",
      "6019  0.967700  0.979335  0.982963  ...  0.926046  0.915251  0.915115   \n",
      "6020  0.979335  0.982963  0.981861  ...  0.915251  0.915115  0.919613   \n",
      "6021  0.982963  0.981861  0.958935  ...  0.915115  0.919613  0.906979   \n",
      "6022  0.981861  0.958935  0.937797  ...  0.919613  0.906979  0.918851   \n",
      "\n",
      "        day 25    day 26    day 27    day 28    day 29    day 30    day 31  \n",
      "0     0.000032  0.000037  0.000030  0.000032  0.000032  0.000032  0.000027  \n",
      "1     0.000037  0.000030  0.000032  0.000032  0.000032  0.000027  0.000041  \n",
      "2     0.000030  0.000032  0.000032  0.000032  0.000027  0.000041  0.000034  \n",
      "3     0.000032  0.000032  0.000032  0.000027  0.000041  0.000034  0.000055  \n",
      "4     0.000032  0.000032  0.000027  0.000041  0.000034  0.000055  0.000146  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "6018  0.915115  0.919613  0.906979  0.918851  0.922834  0.924565  0.914636  \n",
      "6019  0.919613  0.906979  0.918851  0.922834  0.924565  0.914636  0.912642  \n",
      "6020  0.906979  0.918851  0.922834  0.924565  0.914636  0.912642  0.911389  \n",
      "6021  0.918851  0.922834  0.924565  0.914636  0.912642  0.911389  0.915735  \n",
      "6022  0.922834  0.924565  0.914636  0.912642  0.911389  0.915735  0.902426  \n",
      "\n",
      "[6023 rows x 31 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Split into Cells in LSTM format. Specfically, for x you should have data of shape (samples, window_size, feature_size)\n",
    "Create both x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "def saveToLSTMData(x):\n",
    "    datapoint = []\n",
    "    for i in range(1, num_rolling + 1):\n",
    "        timestamp = []\n",
    "        timestamp.append(x['day ' + str(i)])\n",
    "        datapoint.append(timestamp)\n",
    "    data_x.append(datapoint)\n",
    "    data_y.append(x['day ' + str(num_rolling + 1)])\n",
    "\n",
    "df.apply(lambda x : saveToLSTMData(x), axis=1)\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6023, 30, 1)\n",
      "(6023,)\n"
     ]
    }
   ],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Split the data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testing_split = 0.2\n",
    "testing_split = int(len(data_x)*testing_split)\n",
    "train_x = data_x [:-testing_split]\n",
    "test_x = data_x[-testing_split:]\n",
    "train_y = data_y [:-testing_split]\n",
    "test_y = data_y[-testing_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Build the model. Select favorable set of parameters. A good rule of thumb for the number of hidden nodes is:\n",
    "    Hidden_Nodes = (Number of Samples) / (alpha * (input_size + output_size)), where alpha can be some number from 2-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Number of Hidden Node is: 32\n"
     ]
    }
   ],
   "source": [
    "dim = data_x.shape\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "hidden_nodes = int(len(train_x) / (5 * num_rolling))\n",
    "print(\"Suggested Number of Hidden Node is:\", hidden_nodes)\n",
    "model.add(LSTM(hidden_nodes, return_sequences = False, input_shape = (dim[1], dim[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1)) # 1 output: Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                4352      \n",
      "_________________________________________________________________\n",
      "module_wrapper (ModuleWrappe (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,385\n",
      "Trainable params: 4,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Train the model. Record the test loss along the training process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "97/97 [==============================] - 3s 11ms/step - loss: 0.0235 - root_mean_squared_error: 0.0564\n",
      "38/38 [==============================] - 1s 4ms/step - loss: 0.1000 - root_mean_squared_error: 0.1434\n",
      "Epoch 2/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0083 - root_mean_squared_error: 0.0122\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0815 - root_mean_squared_error: 0.1222\n",
      "Epoch 3/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0066 - root_mean_squared_error: 0.0089\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0706 - root_mean_squared_error: 0.1042\n",
      "Epoch 4/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0059 - root_mean_squared_error: 0.0082\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0535 - root_mean_squared_error: 0.0833\n",
      "Epoch 5/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0057 - root_mean_squared_error: 0.0083\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0362 - root_mean_squared_error: 0.0533\n",
      "Epoch 6/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0055 - root_mean_squared_error: 0.0080\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0580 - root_mean_squared_error: 0.0892\n",
      "Epoch 7/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0055 - root_mean_squared_error: 0.0074\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0737 - root_mean_squared_error: 0.1076\n",
      "Epoch 8/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0050 - root_mean_squared_error: 0.0069\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0235 - root_mean_squared_error: 0.0341\n",
      "Epoch 9/100\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0046 - root_mean_squared_error: 0.0064\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.1039 - root_mean_squared_error: 0.1486\n",
      "Epoch 10/100\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.0054 - root_mean_squared_error: 0.0073\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0459 - root_mean_squared_error: 0.0827\n",
      "Epoch 11/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0047 - root_mean_squared_error: 0.0067\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0617 - root_mean_squared_error: 0.0861\n",
      "Epoch 12/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0053 - root_mean_squared_error: 0.0073\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0274 - root_mean_squared_error: 0.0309\n",
      "Epoch 13/100\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0047 - root_mean_squared_error: 0.0071\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0404 - root_mean_squared_error: 0.0593\n",
      "Epoch 14/100\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0061 - root_mean_squared_error: 0.0081\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0498 - root_mean_squared_error: 0.0854\n",
      "Epoch 15/100\n",
      "97/97 [==============================] - 1s 12ms/step - loss: 0.0056 - root_mean_squared_error: 0.0076\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.1060 - root_mean_squared_error: 0.1480\n",
      "Epoch 16/100\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.0041 - root_mean_squared_error: 0.0062\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0244 - root_mean_squared_error: 0.0392\n",
      "Epoch 17/100\n",
      "41/97 [===========>..................] - ETA: 0s - loss: 0.0049 - root_mean_squared_error: 0.0070"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "epochs = 100\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_loss = LambdaCallback(on_epoch_end=lambda batch, logs: train_scores.append(logs['loss']))\n",
    "earlystopper = EarlyStopping(monitor='loss', patience=epochs/10)\n",
    "model.compile(optimizer=Adam(learning_rate=0.05, beta_1=0.9, beta_2=0.999, epsilon=1e-8), loss='mae', metrics=[RootMeanSquaredError()])\n",
    "test_loss = LambdaCallback(on_epoch_end=lambda batch, logs: test_scores.append(model.evaluate(test_x, test_y)[0]))\n",
    "model.fit(train_x, train_y, batch_size=50, epochs=epochs, callbacks=[train_loss, test_loss, earlystopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Prediction. Need to inverse the scaling applied at the begining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result = model.evaluate(test_x,test_y)[1]\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "test_y = scaler.inverse_transform(test_y.reshape(-1,1))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " \n",
    "Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Testing RMSE: \" + str(result))\n",
    "plt.grid()\n",
    "plt.suptitle(\"Learning Curve\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.plot(np.linspace(0,len(train_scores),len(train_scores)), train_scores, linewidth=1, color=\"r\",\n",
    "         label=\"Training loss\")\n",
    "plt.plot(np.linspace(0,len(test_scores),len(test_scores)), test_scores, linewidth=1, color=\"b\",\n",
    "          label=\"Testing loss\")\n",
    "legend = plt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "legend.get_frame().set_facecolor('C0')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Prediction Vs. Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"value\")\n",
    "plt.xlabel(\"samples\")\n",
    "plt.plot(np.linspace(0,len(predictions),len(predictions)), predictions, linewidth=1, color=\"r\",\n",
    "         label=\"Predictions\")\n",
    "plt.plot(np.linspace(0,len(test_y),len(test_y)), test_y, linewidth=1, color=\"b\",\n",
    "          label=\"Actuals\")\n",
    "legend = plt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "legend.get_frame().set_facecolor('C0')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
