{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Amazon Stock Prediction Using Yahoo Finance + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dependencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "g:\\programdata\\anaconda3\\envs\\cs-349-final-project\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\ng:\\programdata\\anaconda3\\envs\\cs-349-final-project\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\ng:\\programdata\\anaconda3\\envs\\cs-349-final-project\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n  stacklevel=1)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup\n",
    "\n",
    "Download data using the Yahoo Finance API"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Read Data using yahoo finance\n",
    "data = yf.download(\n",
    "    tickers=['AMZN'],\n",
    "    # use \"period\" instead of start/end\n",
    "    # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "    # (optional, default is '1mo')\n",
    "    period=\"max\",\n",
    "    # fetch data by interval (including intraday if period < 60 days)\n",
    "    # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "    # (optional, default is '1d')\n",
    "    interval=\"1d\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data.head)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Apply MinMaxScalar, or other normalizing methods of your choice. Since we only use the close prices, we can directly \n",
    "apply it before splitting into training and testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "closes = data['Close'].values\n",
    "scaler = MinMaxScaler()\n",
    "closes_scaled = scaler.fit_transform(closes.reshape(-1, 1))\n",
    "closes_scaled = closes_scaled.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(closes[:5])\n",
    "print(closes_scaled[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Create rolling prices. Continuously create arrays of a set window size and append to a new dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_rolling = 30\n",
    "\n",
    "#Create the 31 day rolling prices\n",
    "header = [\"day \" + str(i) for i in range(1, (num_rolling + 1 + 1))]\n",
    "df = []\n",
    "for i in range(num_rolling, len(closes)):\n",
    "    arr = []\n",
    "    for j in range(i-num_rolling, i+1):\n",
    "        arr.append(closes_scaled[j])\n",
    "    df.append(np.array(arr))\n",
    "df = pd.DataFrame(df, columns=header)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df.head)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Split into Cells in LSTM format. Specfically, for x you should have data of shape (samples, window_size, feature_size)\n",
    "Create both x and y."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "def saveToLSTMData(x):\n",
    "    datapoint = []\n",
    "    for i in range(1, num_rolling + 1):\n",
    "        timestamp = []\n",
    "        timestamp.append(x['day ' + str(i)])\n",
    "        datapoint.append(timestamp)\n",
    "    data_x.append(datapoint)\n",
    "    data_y.append(x['day ' + str(num_rolling + 1)])\n",
    "\n",
    "df.apply(lambda x : saveToLSTMData(x), axis=1)\n",
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data_x.shape)\n",
    "print(data_y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Split the data into training and testing."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_split = 0.2\n",
    "testing_split = int(len(data_x)*testing_split)\n",
    "train_x = data_x [:-testing_split]\n",
    "test_x = data_x[-testing_split:]\n",
    "train_y = data_y [:-testing_split]\n",
    "test_y = data_y[-testing_split:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train LSTM Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Build the model. Select favorable set of parameters. A good rule of thumb for the number of hidden nodes is:\n",
    "    Hidden_Nodes = (Number of Samples) / (alpha * (input_size + output_size)), where alpha can be some number from 2-10."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dim = data_x.shape\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "dense_nodes = 5\n",
    "hidden_nodes = int(len(train_x) / (2 * (dense_nodes + num_rolling)))\n",
    "print(\"Suggested Number of Hidden Node is:\", hidden_nodes)\n",
    "model.add(LSTM(hidden_nodes, return_sequences = False, input_shape = (dim[1], dim[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(dense_nodes))\n",
    "model.add(Dense(1)) # 1 output: Price"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Train the model. Record the test loss along the training process.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train\n",
    "epochs = 100\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "train_loss = LambdaCallback(on_epoch_end=lambda batch, logs: train_scores.append(logs['loss']))\n",
    "earlystopper = EarlyStopping(monitor='loss', patience=epochs/10)\n",
    "model.compile(optimizer=Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8), loss='mae', metrics=[RootMeanSquaredError()])\n",
    "test_loss = LambdaCallback(on_epoch_end=lambda batch, logs: test_scores.append(model.evaluate(test_x, test_y)[0]))\n",
    "model.fit(train_x, train_y, batch_size=50, epochs=epochs, callbacks=[train_loss, test_loss, earlystopper])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Prediction. Need to inverse the scaling applied at the begining."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = model.evaluate(test_x,test_y)[1]\n",
    "predictions = model.predict(test_x)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "test_y = scaler.inverse_transform(test_y.reshape(-1,1))\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "Learning Curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Testing RMSE: \" + str(result))\n",
    "plt.grid()\n",
    "plt.suptitle(\"Learning Curve\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.plot(np.linspace(0,len(train_scores),len(train_scores)), train_scores, linewidth=1, color=\"r\",\n",
    "         label=\"Training loss\")\n",
    "plt.plot(np.linspace(0,len(test_scores),len(test_scores)), test_scores, linewidth=1, color=\"b\",\n",
    "          label=\"Testing loss\")\n",
    "legend = plt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "legend.get_frame().set_facecolor('C0')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "Prediction Vs. Actual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.title(\"Predicted vs Actual\")\n",
    "plt.grid()\n",
    "plt.ylabel(\"value\")\n",
    "plt.xlabel(\"samples\")\n",
    "plt.plot(np.linspace(0,len(predictions),len(predictions)), predictions, linewidth=1, color=\"r\",\n",
    "         label=\"Predictions\")\n",
    "plt.plot(np.linspace(0,len(test_y),len(test_y)), test_y, linewidth=1, color=\"b\",\n",
    "          label=\"Actuals\")\n",
    "legend = plt.legend(loc='upper right', shadow=True, fontsize='medium')\n",
    "legend.get_frame().set_facecolor('C0')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "This seems like a good prediction scheme at first glance, however, it really did not learn anythin that useful. The model\n",
    "learns to simply adhere to the previous day's price since it's probably gonna be super close. Therefore, this should not\n",
    "be used as a tool to actually predict."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}